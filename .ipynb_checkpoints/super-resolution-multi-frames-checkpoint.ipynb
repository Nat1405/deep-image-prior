{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rlxz8rh1f5Os"
   },
   "source": [
    "Code for **super-resolution** (figures $1$ and $5$ from main paper).. Change `factor` to $8$ to reproduce images from fig. $9$ from supmat.\n",
    "\n",
    "You can play with parameters and see how they affect the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "V9Uei2zif5Ox",
    "outputId": "ec33c3fa-1624-48f5-af27-6019abcf9df8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'deep-image-prior' already exists and is not an empty directory.\n",
      "mv: cannot stat 'deep-image-prior/*': No such file or directory\n",
      "Requirement already up-to-date: tensorboard in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.32.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (50.3.0)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.17.2)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.12.4)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.2.2)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.35.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.1.1)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.6)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "*Uncomment if running on colab* \n",
    "Set Runtime -> Change runtime type -> Under Hardware Accelerator select GPU in Google Colab \n",
    "\"\"\"\n",
    "!git clone --single-branch --branch jupiter_niri https://github.com/Nat1405/deep-image-prior\n",
    "!mv deep-image-prior/* ./\n",
    "!pip install -U tensorboard \n",
    "!rm -r runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7HF5K7l0f5O8"
   },
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B-v5XPV6f5O9"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "from models import *\n",
    "\n",
    "import torch\n",
    "import torch.optim\n",
    "\n",
    "from skimage.measure import compare_psnr\n",
    "from skimage.measure import compare_mse\n",
    "from models.downsampler import Downsampler\n",
    "\n",
    "from utils.sr_utils import *\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import astropy.io.fits as fits\n",
    "\n",
    "def put_in_center(img_np, target_size):\n",
    "    img_out = np.zeros([3, target_size[0], target_size[1]])\n",
    "\n",
    "    bbox = [\n",
    "            int((target_size[0] - img_np.shape[1]) / 2),\n",
    "            int((target_size[1] - img_np.shape[2]) / 2),\n",
    "            int((target_size[0] + img_np.shape[1]) / 2),\n",
    "            int((target_size[1] + img_np.shape[2]) / 2),\n",
    "    ]\n",
    "\n",
    "    img_out[:, bbox[0]:bbox[2], bbox[1]:bbox[3]] = img_np\n",
    "\n",
    "    return img_out\n",
    "\n",
    "\n",
    "def load_LR_HR_imgs_sr(fname, imsize, factor, enforse_div32=None):\n",
    "    '''Loads an image, resizes it, center crops and downscales.\n",
    "\n",
    "    Args: \n",
    "        fname: path to the image\n",
    "        imsize: new size for the image, -1 for no resizing\n",
    "        factor: downscaling factor\n",
    "        enforse_div32: if 'CROP' center crops an image, so that its dimensions are divisible by 32.\n",
    "    '''\n",
    "    img_orig_pil, img_orig_np = get_image(fname, -1)\n",
    "\n",
    "    if imsize != -1:\n",
    "        img_orig_pil, img_orig_np = get_image(fname, imsize)\n",
    "\n",
    "    # For comparison with GT\n",
    "    if enforse_div32 == 'CROP':\n",
    "        new_size = (img_orig_pil.size[0] - img_orig_pil.size[0] % 32, \n",
    "                    img_orig_pil.size[1] - img_orig_pil.size[1] % 32)\n",
    "\n",
    "        bbox = [\n",
    "                (img_orig_pil.size[0] - new_size[0])/2, \n",
    "                (img_orig_pil.size[1] - new_size[1])/2,\n",
    "                (img_orig_pil.size[0] + new_size[0])/2,\n",
    "                (img_orig_pil.size[1] + new_size[1])/2,\n",
    "        ]\n",
    "\n",
    "        img_HR_pil = img_orig_pil.crop(bbox)\n",
    "        img_HR_np = pil_to_np(img_HR_pil)\n",
    "    else:\n",
    "        img_HR_pil, img_HR_np = img_orig_pil, img_orig_np\n",
    "\n",
    "    LR_size = [\n",
    "               img_HR_pil.size[0] // factor, \n",
    "               img_HR_pil.size[1] // factor\n",
    "    ]\n",
    "\n",
    "    img_LR_pil = img_HR_pil.resize(LR_size, Image.ANTIALIAS)\n",
    "    img_LR_np = pil_to_np(img_LR_pil)\n",
    "\n",
    "    print('HR and LR resolutions: %s, %s' % (str(img_HR_pil.size), str (img_LR_pil.size)))\n",
    "\n",
    "    return {\n",
    "                'orig_pil': img_orig_pil,\n",
    "                'orig_np':  img_orig_np,\n",
    "                'LR_pil':  img_LR_pil, \n",
    "                'LR_np': img_LR_np,\n",
    "                'HR_pil':  img_HR_pil, \n",
    "                'HR_np': img_HR_np\n",
    "           }\n",
    "\n",
    "def load_multiple_LR_HR_imgs_sr(fnames):\n",
    "    img_LR_nps = []\n",
    "    for fname in fnames:\n",
    "        with fits.open(fname) as hdu_list:\n",
    "            img_LR_nps.append(np.flipud(hdu_list['SCI'].data.astype(np.float32)).copy())\n",
    "\n",
    "    return img_LR_nps\n",
    "\n",
    "def tv_loss(x, beta = 0.5):\n",
    "    '''Calculates TV loss for an image `x`.\n",
    "\n",
    "    Args:\n",
    "        x: image, torch.Variable of torch.Tensor\n",
    "        beta: See https://arxiv.org/abs/1412.0035 (fig. 2) to see effect of `beta` \n",
    "    '''\n",
    "    dh = torch.pow(x[:,:,:,1:] - x[:,:,:,:-1], 2)\n",
    "    dw = torch.pow(x[:,:,1:,:] - x[:,:,:-1,:], 2)\n",
    "\n",
    "    return torch.sum(torch.pow(dh[:, :, :-1] + dw[:, :, :, :-1], beta))\n",
    "\n",
    "def get_params(opt_over, net, net_input, downsampler=None):\n",
    "    '''Returns parameters that we want to optimize over.\n",
    "\n",
    "    Args:\n",
    "        opt_over: comma separated list, e.g. \"net,input\" or \"net\"\n",
    "        net: network\n",
    "        net_input: torch.Tensor that stores input `z`\n",
    "    '''\n",
    "    opt_over_list = opt_over.split(',')\n",
    "    params = []\n",
    "    \n",
    "    for opt in opt_over_list:\n",
    "    \n",
    "        if opt == 'net':\n",
    "            params += [x for x in net.parameters() ]\n",
    "        elif  opt=='down':\n",
    "            assert downsampler is not None\n",
    "            params = [x for x in downsampler.parameters()]\n",
    "        elif opt == 'input':\n",
    "            net_input.requires_grad = True\n",
    "            params += [net_input]\n",
    "        else:\n",
    "            assert False, 'what is it?'\n",
    "            \n",
    "    return params\n",
    "\n",
    "def fill_noise(x, noise_type):\n",
    "    \"\"\"Fills tensor `x` with noise of type `noise_type`.\"\"\"\n",
    "    if noise_type == 'u':\n",
    "        x.uniform_()\n",
    "    elif noise_type == 'n':\n",
    "        x.normal_() \n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "def get_noise(input_depth, method, spatial_size, noise_type='u', var=1./10):\n",
    "    \"\"\"Returns a pytorch.Tensor of size (1 x `input_depth` x `spatial_size[0]` x `spatial_size[1]`) \n",
    "    initialized in a specific way.\n",
    "    Args:\n",
    "        input_depth: number of channels in the tensor\n",
    "        method: `noise` for fillting tensor with noise; `meshgrid` for np.meshgrid\n",
    "        spatial_size: spatial size of the tensor to initialize\n",
    "        noise_type: 'u' for uniform; 'n' for normal\n",
    "        var: a factor, a noise will be multiplicated by. Basically it is standard deviation scaler. \n",
    "    \"\"\"\n",
    "    if isinstance(spatial_size, int):\n",
    "        spatial_size = (spatial_size, spatial_size)\n",
    "    if method == 'noise':\n",
    "        shape = [1, input_depth, spatial_size[0], spatial_size[1]]\n",
    "        net_input = torch.zeros(shape)\n",
    "        \n",
    "        fill_noise(net_input, noise_type)\n",
    "        net_input *= var            \n",
    "    elif method == 'meshgrid': \n",
    "        assert input_depth == 2\n",
    "        X, Y = np.meshgrid(np.arange(0, spatial_size[1])/float(spatial_size[1]-1), np.arange(0, spatial_size[0])/float(spatial_size[0]-1))\n",
    "        meshgrid = np.concatenate([X[None,:], Y[None,:]])\n",
    "        net_input=  np_to_torch(meshgrid)\n",
    "    else:\n",
    "        assert False\n",
    "        \n",
    "    return net_input\n",
    "\n",
    "def pil_to_np(img_PIL):\n",
    "    '''Converts image in PIL format to np.array.\n",
    "    \n",
    "    From W x H x C [0...255] to C x W x H [0..1]\n",
    "    '''\n",
    "    ar = np.array(img_PIL)\n",
    "\n",
    "    if len(ar.shape) == 3:\n",
    "        ar = ar.transpose(2,0,1)\n",
    "    else:\n",
    "        ar = ar[None, ...]\n",
    "\n",
    "    return ar.astype(np.float32) / 255.\n",
    "\n",
    "def np_to_pil(img_np): \n",
    "    '''Converts image in np.array format to PIL image.\n",
    "    \n",
    "    From C x W x H [0..1] to  W x H x C [0...255]\n",
    "    '''\n",
    "    ar = np.clip(img_np*255,0,255).astype(np.uint8)\n",
    "    \n",
    "    if img_np.shape[0] == 1:\n",
    "        ar = ar[0]\n",
    "    else:\n",
    "        ar = ar.transpose(1, 2, 0)\n",
    "\n",
    "    return Image.fromarray(ar)\n",
    "\n",
    "def np_to_torch(img_np):\n",
    "    '''Converts image in numpy.array to torch.Tensor.\n",
    "\n",
    "    From C x W x H [0..1] to  C x W x H [0..1]\n",
    "    '''\n",
    "    return torch.from_numpy(img_np)[None, :]\n",
    "\n",
    "def torch_to_np(img_var):\n",
    "    '''Converts an image in torch.Tensor format to np.array.\n",
    "\n",
    "    From 1 x C x W x H [0..1] to  C x W x H [0..1]\n",
    "    '''\n",
    "    return img_var.detach().cpu().numpy()[0]\n",
    "\n",
    "\n",
    "def optimize(optimizer_type, parameters, closure, LR, num_iter):\n",
    "    \"\"\"Runs optimization loop.\n",
    "\n",
    "    Args:\n",
    "        optimizer_type: 'LBFGS' of 'adam'\n",
    "        parameters: list of Tensors to optimize over\n",
    "        closure: function, that returns loss variable\n",
    "        LR: learning rate\n",
    "        num_iter: number of iterations \n",
    "    \"\"\"\n",
    "    if optimizer_type == 'LBFGS':\n",
    "        # Do several steps with adam first\n",
    "        optimizer = torch.optim.Adam(parameters, lr=0.001)\n",
    "        for j in range(100):\n",
    "            optimizer.zero_grad()\n",
    "            closure()\n",
    "            optimizer.step()\n",
    "\n",
    "        print('Starting optimization with LBFGS')        \n",
    "        def closure2():\n",
    "            optimizer.zero_grad()\n",
    "            return closure()\n",
    "        optimizer = torch.optim.LBFGS(parameters, max_iter=num_iter, lr=LR, tolerance_grad=-1, tolerance_change=-1)\n",
    "        optimizer.step(closure2)\n",
    "\n",
    "    elif optimizer_type == 'adam':\n",
    "        print('Starting optimization with ADAM')\n",
    "        optimizer = torch.optim.Adam(parameters, lr=LR)\n",
    "        \n",
    "        for j in range(num_iter):\n",
    "            optimizer.zero_grad()\n",
    "            closure()\n",
    "            optimizer.step()\n",
    "    else:\n",
    "        assert False\n",
    "        \n",
    "def get_net(input_depth, NET_TYPE, pad, upsample_mode, n_channels=3, act_fun='LeakyReLU', skip_n33d=128, skip_n33u=128, skip_n11=4, num_scales=5, downsample_mode='stride'):\n",
    "    if NET_TYPE == 'ResNet':\n",
    "        # TODO\n",
    "        net = ResNet(input_depth, 3, 10, 16, 1, nn.BatchNorm2d, False)\n",
    "    elif NET_TYPE == 'skip':\n",
    "        net = skip(input_depth, n_channels, num_channels_down = [skip_n33d]*num_scales if isinstance(skip_n33d, int) else skip_n33d,\n",
    "                                            num_channels_up =   [skip_n33u]*num_scales if isinstance(skip_n33u, int) else skip_n33u,\n",
    "                                            num_channels_skip = [skip_n11]*num_scales if isinstance(skip_n11, int) else skip_n11, \n",
    "                                            upsample_mode=upsample_mode, downsample_mode=downsample_mode,\n",
    "                                            need_sigmoid=True, need_bias=True, pad=pad, act_fun=act_fun)\n",
    "\n",
    "    elif NET_TYPE == 'texture_nets':\n",
    "        net = get_texture_nets(inp=input_depth, ratios = [32, 16, 8, 4, 2, 1], fill_noise=False,pad=pad)\n",
    "\n",
    "    elif NET_TYPE =='UNet':\n",
    "        net = UNet(num_input_channels=input_depth, num_output_channels=3, \n",
    "                   feature_scale=4, more_layers=0, concat_x=False,\n",
    "                   upsample_mode=upsample_mode, pad=pad, norm_layer=nn.BatchNorm2d, need_sigmoid=True, need_bias=True)\n",
    "    elif NET_TYPE == 'identity':\n",
    "        assert input_depth == 3\n",
    "        net = nn.Sequential()\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "    return net\n",
    "\n",
    "class ListModule(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(ListModule, self).__init__()\n",
    "        idx = 0\n",
    "        for module in args:\n",
    "            self.add_module(str(idx), module)\n",
    "            idx += 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self._modules):\n",
    "            raise IndexError('index {} is out of range'.format(idx))\n",
    "        if idx < 0: \n",
    "            idx = len(self) + idx\n",
    "\n",
    "        it = iter(self._modules.values())\n",
    "        for i in range(idx):\n",
    "            next(it)\n",
    "        return next(it)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self._modules.values())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._modules)\n",
    "\n",
    "def add_module(self, module):\n",
    "    self.add_module(str(len(self) + 1), module)\n",
    "    \n",
    "torch.nn.Module.add = add_module\n",
    "\n",
    "class Concat(nn.Module):\n",
    "    def __init__(self, dim, *args):\n",
    "        super(Concat, self).__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "        for idx, module in enumerate(args):\n",
    "            self.add_module(str(idx), module)\n",
    "\n",
    "    def forward(self, input):\n",
    "        inputs = []\n",
    "        for module in self._modules.values():\n",
    "            inputs.append(module(input))\n",
    "\n",
    "        inputs_shapes2 = [x.shape[2] for x in inputs]\n",
    "        inputs_shapes3 = [x.shape[3] for x in inputs]        \n",
    "\n",
    "        if np.all(np.array(inputs_shapes2) == min(inputs_shapes2)) and np.all(np.array(inputs_shapes3) == min(inputs_shapes3)):\n",
    "            inputs_ = inputs\n",
    "        else:\n",
    "            target_shape2 = min(inputs_shapes2)\n",
    "            target_shape3 = min(inputs_shapes3)\n",
    "\n",
    "            inputs_ = []\n",
    "            for inp in inputs: \n",
    "                diff2 = (inp.size(2) - target_shape2) // 2 \n",
    "                diff3 = (inp.size(3) - target_shape3) // 2 \n",
    "                inputs_.append(inp[:, :, diff2: diff2 + target_shape2, diff3:diff3 + target_shape3])\n",
    "\n",
    "        return torch.cat(inputs_, dim=self.dim)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._modules)\n",
    "\n",
    "\n",
    "class GenNoise(nn.Module):\n",
    "    def __init__(self, dim2):\n",
    "        super(GenNoise, self).__init__()\n",
    "        self.dim2 = dim2\n",
    "\n",
    "    def forward(self, input):\n",
    "        a = list(input.size())\n",
    "        a[1] = self.dim2\n",
    "        # print (input.data.type())\n",
    "\n",
    "        b = torch.zeros(a).type_as(input.data)\n",
    "        b.normal_()\n",
    "\n",
    "        x = torch.autograd.Variable(b)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    \"\"\"\n",
    "        https://arxiv.org/abs/1710.05941\n",
    "        The hype was so huge that I could not help but try it\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Swish, self).__init__()\n",
    "        self.s = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.s(x)\n",
    "\n",
    "\n",
    "def act(act_fun = 'LeakyReLU'):\n",
    "    '''\n",
    "        Either string defining an activation function or module (e.g. nn.ReLU)\n",
    "    '''\n",
    "    if isinstance(act_fun, str):\n",
    "        if act_fun == 'LeakyReLU':\n",
    "            return nn.LeakyReLU(0.2, inplace=True)\n",
    "        elif act_fun == 'Swish':\n",
    "            return Swish()\n",
    "        elif act_fun == 'ELU':\n",
    "            return nn.ELU()\n",
    "        elif act_fun == 'none':\n",
    "            return nn.Sequential()\n",
    "        else:\n",
    "            assert False\n",
    "    else:\n",
    "        return act_fun()\n",
    "\n",
    "\n",
    "def bn(num_features):\n",
    "    return nn.BatchNorm2d(num_features)\n",
    "\n",
    "\n",
    "def conv(in_f, out_f, kernel_size, stride=1, bias=True, pad='zero', downsample_mode='stride'):\n",
    "    downsampler = None\n",
    "    if stride != 1 and downsample_mode != 'stride':\n",
    "\n",
    "        if downsample_mode == 'avg':\n",
    "            downsampler = nn.AvgPool2d(stride, stride)\n",
    "        elif downsample_mode == 'max':\n",
    "            downsampler = nn.MaxPool2d(stride, stride)\n",
    "        elif downsample_mode  in ['lanczos2', 'lanczos3']:\n",
    "            downsampler = Downsampler(n_planes=out_f, factor=stride, kernel_type=downsample_mode, phase=0.5, preserve_size=True)\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "        stride = 1\n",
    "\n",
    "    padder = None\n",
    "    to_pad = int((kernel_size - 1) / 2)\n",
    "    if pad == 'reflection':\n",
    "        padder = nn.ReflectionPad2d(to_pad)\n",
    "        to_pad = 0\n",
    "  \n",
    "    convolver = nn.Conv2d(in_f, out_f, kernel_size, stride, padding=to_pad, bias=bias)\n",
    "\n",
    "\n",
    "    layers = filter(lambda x: x is not None, [padder, convolver, downsampler])\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class Downsampler(nn.Module):\n",
    "    '''\n",
    "        http://www.realitypixels.com/turk/computergraphics/ResamplingFilters.pdf\n",
    "    '''\n",
    "    def __init__(self, n_planes, factor, kernel_type, phase=0, kernel_width=None, support=None, sigma=None, preserve_size=False):\n",
    "        super(Downsampler, self).__init__()\n",
    "        \n",
    "        assert phase in [0, 0.5], 'phase should be 0 or 0.5'\n",
    "\n",
    "        if kernel_type == 'lanczos2':\n",
    "            support = 2\n",
    "            kernel_width = 4 * factor + 1\n",
    "            kernel_type_ = 'lanczos'\n",
    "\n",
    "        elif kernel_type == 'lanczos3':\n",
    "            support = 3\n",
    "            kernel_width = 6 * factor + 1\n",
    "            kernel_type_ = 'lanczos'\n",
    "\n",
    "        elif kernel_type == 'gauss12':\n",
    "            kernel_width = 7\n",
    "            sigma = 1/2\n",
    "            kernel_type_ = 'gauss'\n",
    "\n",
    "        elif kernel_type == 'gauss1sq2':\n",
    "            kernel_width = 9\n",
    "            sigma = 1./np.sqrt(2)\n",
    "            kernel_type_ = 'gauss'\n",
    "\n",
    "        elif kernel_type in ['lanczos', 'gauss', 'box']:\n",
    "            kernel_type_ = kernel_type\n",
    "\n",
    "        else:\n",
    "            assert False, 'wrong name kernel'\n",
    "            \n",
    "            \n",
    "        # note that `kernel width` will be different to actual size for phase = 1/2\n",
    "        self.kernel = get_kernel(factor, kernel_type_, phase, kernel_width, support=support, sigma=sigma)\n",
    "        \n",
    "        downsampler = nn.Conv2d(n_planes, n_planes, kernel_size=self.kernel.shape, stride=factor, padding=0)\n",
    "        downsampler.weight.data[:] = 0\n",
    "        downsampler.bias.data[:] = 0\n",
    "\n",
    "        kernel_torch = torch.from_numpy(self.kernel)\n",
    "        for i in range(n_planes):\n",
    "            downsampler.weight.data[i, i] = kernel_torch       \n",
    "\n",
    "        self.downsampler_ = downsampler\n",
    "\n",
    "        if preserve_size:\n",
    "\n",
    "            if  self.kernel.shape[0] % 2 == 1: \n",
    "                pad = int((self.kernel.shape[0] - 1) / 2.)\n",
    "            else:\n",
    "                pad = int((self.kernel.shape[0] - factor) / 2.)\n",
    "                \n",
    "            self.padding = nn.ReplicationPad2d(pad)\n",
    "        \n",
    "        self.preserve_size = preserve_size\n",
    "        \n",
    "    def forward(self, input):\n",
    "        if self.preserve_size:\n",
    "            x = self.padding(input)\n",
    "        else:\n",
    "            x= input\n",
    "        self.x = x\n",
    "        return self.downsampler_(x)\n",
    "        \n",
    "def get_kernel(factor, kernel_type, phase, kernel_width, support=None, sigma=None):\n",
    "    assert kernel_type in ['lanczos', 'gauss', 'box']\n",
    "    \n",
    "    # factor  = float(factor)\n",
    "    if phase == 0.5 and kernel_type != 'box': \n",
    "        kernel = np.zeros([kernel_width - 1, kernel_width - 1])\n",
    "    else:\n",
    "        kernel = np.zeros([kernel_width, kernel_width])\n",
    "    \n",
    "        \n",
    "    if kernel_type == 'box':\n",
    "        assert phase == 0.5, 'Box filter is always half-phased'\n",
    "        kernel[:] = 1./(kernel_width * kernel_width)\n",
    "        \n",
    "    elif kernel_type == 'gauss': \n",
    "        assert sigma, 'sigma is not specified'\n",
    "        assert phase != 0.5, 'phase 1/2 for gauss not implemented'\n",
    "        \n",
    "        center = (kernel_width + 1.)/2.\n",
    "        print(center, kernel_width)\n",
    "        sigma_sq =  sigma * sigma\n",
    "        \n",
    "        for i in range(1, kernel.shape[0] + 1):\n",
    "            for j in range(1, kernel.shape[1] + 1):\n",
    "                di = (i - center)/2.\n",
    "                dj = (j - center)/2.\n",
    "                kernel[i - 1][j - 1] = np.exp(-(di * di + dj * dj)/(2 * sigma_sq))\n",
    "                kernel[i - 1][j - 1] = kernel[i - 1][j - 1]/(2. * np.pi * sigma_sq)\n",
    "    elif kernel_type == 'lanczos': \n",
    "        assert support, 'support is not specified'\n",
    "        center = (kernel_width + 1) / 2.\n",
    "\n",
    "        for i in range(1, kernel.shape[0] + 1):\n",
    "            for j in range(1, kernel.shape[1] + 1):\n",
    "                \n",
    "                if phase == 0.5:\n",
    "                    di = abs(i + 0.5 - center) / factor  \n",
    "                    dj = abs(j + 0.5 - center) / factor \n",
    "                else:\n",
    "                    di = abs(i - center) / factor\n",
    "                    dj = abs(j - center) / factor\n",
    "                \n",
    "                \n",
    "                pi_sq = np.pi * np.pi\n",
    "\n",
    "                val = 1\n",
    "                if di != 0:\n",
    "                    val = val * support * np.sin(np.pi * di) * np.sin(np.pi * di / support)\n",
    "                    val = val / (np.pi * np.pi * di * di)\n",
    "                \n",
    "                if dj != 0:\n",
    "                    val = val * support * np.sin(np.pi * dj) * np.sin(np.pi * dj / support)\n",
    "                    val = val / (np.pi * np.pi * dj * dj)\n",
    "                \n",
    "                kernel[i - 1][j - 1] = val\n",
    "            \n",
    "        \n",
    "    else:\n",
    "        assert False, 'wrong method name'\n",
    "    \n",
    "    kernel /= kernel.sum()\n",
    "    \n",
    "    return kernel\n",
    "\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "use_GPU = False\n",
    "\n",
    "torch.backends.cudnn.enabled = use_GPU\n",
    "torch.backends.cudnn.benchmark = use_GPU\n",
    "if use_GPU:\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    dtype = torch.FloatTensor\n",
    "    \n",
    "imsize = 256\n",
    "factor = 4 # 8\n",
    "enforse_div32 = 'CROP' # we usually need the dimensions to be divisible by a power of two (32 in this case)\n",
    "PLOT = True\n",
    "\n",
    "\n",
    "path_to_images = 'data/sr/jupiter_frames'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "llX9hrvLf5PF"
   },
   "source": [
    "# Load image and baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "GpyfEuHTf5PG",
    "outputId": "18615c5b-0c34-4f7e-855e-712ce0c40e99"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Starts here\n",
    "import glob\n",
    "from PIL import Image\n",
    "import astropy.visualization\n",
    "\n",
    "frames = glob.glob(os.path.join(path_to_images, \"*.fits\"))\n",
    "\n",
    "multi_frames_np = load_multiple_LR_HR_imgs_sr(frames[:8])\n",
    "\n",
    "# Resize frames to IMSIZE\n",
    "IMSIZE = 256\n",
    "multi_frames_HR_np = [np.array(Image.fromarray(x).resize((IMSIZE,IMSIZE), Image.ANTIALIAS)) for x in multi_frames_np]\n",
    "multi_frames_LR_np = [np.array(Image.fromarray(x).resize((IMSIZE//4,IMSIZE//4), Image.ANTIALIAS)) for x in multi_frames_np]\n",
    "# Reduce resolution by factor of 4\n",
    "\n",
    "if PLOT:\n",
    "    stacked = np.expand_dims(np.hstack(multi_frames_LR_np), 0)\n",
    "    Interval = astropy.visualization.PercentileInterval(99.0)\n",
    "    stacked = Interval(stacked)\n",
    "    writer.add_image('Training Frames', torch.tensor(stacked), 0)\n",
    "    plt.imshow(stacked[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NfPKjWX4f5PS"
   },
   "source": [
    "# Set up parameters and net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fok0UIz5f5PT"
   },
   "outputs": [],
   "source": [
    "input_depth = 1\n",
    " \n",
    "INPUT =     'noise'\n",
    "pad   =     'reflection'\n",
    "OPT_OVER =  'net'\n",
    "KERNEL_TYPE='lanczos2'\n",
    "\n",
    "LR = 0.01\n",
    "tv_weight = 0.0\n",
    "\n",
    "OPTIMIZER = 'adam'\n",
    "\n",
    "num_iter = 100\n",
    "reg_noise_std = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XnCNgy_Zf5Pb"
   },
   "outputs": [],
   "source": [
    "net_input = get_noise(input_depth, INPUT, (IMSIZE, IMSIZE)).type(dtype).detach()\n",
    "\n",
    "NET_TYPE = 'skip' # UNet, ResNet, skip\n",
    "net = get_net(input_depth, NET_TYPE, pad,\n",
    "              n_channels=1,\n",
    "              skip_n33d=128, \n",
    "              skip_n33u=128, \n",
    "              skip_n11=4, \n",
    "              num_scales=5,\n",
    "              upsample_mode='bilinear').type(dtype)\n",
    "\n",
    "# Losses\n",
    "mse = torch.nn.MSELoss().type(dtype)\n",
    "\n",
    "img_LR_vars = [np_to_torch(x).type(dtype) for x in multi_frames_LR_np]\n",
    "\n",
    "downsampler = Downsampler(n_planes=1, factor=factor, kernel_type=KERNEL_TYPE, phase=0.5, preserve_size=True).type(dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yz8Yd3-af5Pj"
   },
   "source": [
    "# Define closure and optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f57dao5Mf5Pk"
   },
   "outputs": [],
   "source": [
    "def closure():\n",
    "    global i, net_input\n",
    "    \n",
    "    if reg_noise_std > 0:\n",
    "        net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "\n",
    "    out_HR = net(net_input)\n",
    "    out_LR = downsampler(out_HR)\n",
    "\n",
    "    # Train on a random frame every time by hashing current index\n",
    "    index = hash(i) % len(img_LR_vars)\n",
    "    total_loss = mse(out_LR[0,:,:], img_LR_vars[index]) \n",
    "    \n",
    "    if tv_weight > 0:\n",
    "        total_loss += tv_weight * tv_loss(out_HR)\n",
    "        \n",
    "    total_loss.backward()\n",
    "\n",
    "    # Log\n",
    "    #psnr_LR = compare_psnr(imgs['LR_np'], torch_to_np(out_LR))\n",
    "    #psnr_HR = compare_psnr(imgs['HR_np'], torch_to_np(out_HR))\n",
    "    #print ('Iteration %05d    PSNR_LR %.3f   PSNR_HR %.3f' % (i, psnr_LR, psnr_HR), '\\r', end='')\n",
    "    #target_loss = compare_mse(imgs['HR_np'], torch_to_np(out_HR))\n",
    "                      \n",
    "    # History\n",
    "    #psnr_history.append([psnr_LR, psnr_HR])\n",
    "    #training_loss_history.append(total_loss.item())\n",
    "    #target_loss_history.append(target_loss)\n",
    "\n",
    "    # TensorBoard History\n",
    "    #writer.add_scalar('PSNR LR', psnr_LR, i)\n",
    "    #writer.add_scalar('PSNR HR', psnr_HR, i)\n",
    "    #writer.add_scalar('Training Loss', total_loss.item(), i)\n",
    "    #writer.add_scalar('Target Loss', target_loss, i)\n",
    "\n",
    "    for name, param in net.named_parameters():\n",
    "        writer.add_histogram('Parameter {}'.format(name), param.flatten(), i)\n",
    "    \n",
    "    if PLOT and i % 1 == 0:\n",
    "        Interval = astropy.visualization.PercentileInterval(99.0)\n",
    "        out_HR_np = Interval(torch_to_np(out_HR))[0]\n",
    "        out_LR_np = torch_to_np(out_LR)\n",
    "        \n",
    "        Interval = astropy.visualization.PercentileInterval(99.0)\n",
    "        images = [np.expand_dims(np.hstack([Interval(x), out_HR_np]), 0) for x in multi_frames_HR_np]\n",
    "        images_torch = [torch.from_numpy(x) for x in images]\n",
    "        for j in range(len(images_torch)):\n",
    "            writer.add_image('Training frame {}'.format(j), images_torch[j], i)\n",
    "        #plot_image_grid([imgs['HR_np'], imgs['bicubic_np'], np.clip(out_HR_np, 0, 1)], factor=13, nrow=3)\n",
    "    \n",
    "    print(\"{}  {}\".format(i, index))\n",
    "    i += 1\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "IR78yx5Kf5Px",
    "outputId": "97615fc2-daab-4171-e5c5-1634a9f856e4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration / Frame used\n",
      "Starting optimization with ADAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nat/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  0\n",
      "1  1\n",
      "2  2\n",
      "3  3\n",
      "4  4\n",
      "5  5\n",
      "6  6\n",
      "7  7\n",
      "8  0\n",
      "9  1\n",
      "10  2\n",
      "11  3\n",
      "12  4\n",
      "13  5\n",
      "14  6\n",
      "15  7\n",
      "16  0\n",
      "17  1\n",
      "18  2\n",
      "19  3\n",
      "20  4\n",
      "21  5\n",
      "22  6\n",
      "23  7\n",
      "24  0\n",
      "25  1\n",
      "26  2\n",
      "27  3\n",
      "28  4\n",
      "29  5\n",
      "30  6\n",
      "31  7\n",
      "32  0\n",
      "33  1\n",
      "34  2\n",
      "35  3\n",
      "36  4\n",
      "37  5\n",
      "38  6\n",
      "39  7\n",
      "40  0\n",
      "41  1\n",
      "42  2\n",
      "43  3\n",
      "44  4\n",
      "45  5\n",
      "46  6\n",
      "47  7\n",
      "48  0\n",
      "49  1\n",
      "50  2\n",
      "51  3\n",
      "52  4\n",
      "53  5\n",
      "54  6\n",
      "55  7\n",
      "56  0\n",
      "57  1\n",
      "58  2\n",
      "59  3\n",
      "60  4\n",
      "61  5\n",
      "62  6\n",
      "63  7\n",
      "64  0\n",
      "65  1\n",
      "66  2\n",
      "67  3\n",
      "68  4\n",
      "69  5\n",
      "70  6\n",
      "71  7\n",
      "72  0\n",
      "73  1\n",
      "74  2\n",
      "75  3\n",
      "76  4\n",
      "77  5\n",
      "78  6\n",
      "79  7\n",
      "80  0\n",
      "81  1\n",
      "82  2\n",
      "83  3\n",
      "84  4\n",
      "85  5\n",
      "86  6\n",
      "87  7\n",
      "88  0\n",
      "89  1\n",
      "90  2\n",
      "91  3\n",
      "92  4\n",
      "93  5\n",
      "94  6\n",
      "95  7\n",
      "96  0\n",
      "97  1\n",
      "98  2\n",
      "99  3\n"
     ]
    }
   ],
   "source": [
    "psnr_history = [] \n",
    "training_loss_history = []\n",
    "target_loss_history = []\n",
    "net_input_saved = net_input.detach().clone()\n",
    "noise = net_input.detach().clone()\n",
    "\n",
    "i = 0\n",
    "p = get_params(OPT_OVER, net, net_input)\n",
    "print(\"Iteration / Frame used\")\n",
    "optimize(OPTIMIZER, p, closure, LR, num_iter)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lc_kMoEt0D22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 41282), started 1:28:44 ago. (Use '!kill 41282' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a5d5ce20b3f7dff9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a5d5ce20b3f7dff9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Launch tensorboard to review results\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "super-resolution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
